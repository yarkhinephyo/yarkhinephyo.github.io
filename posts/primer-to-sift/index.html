<!doctype html><html lang="en" data-mode="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="Primer to Scale-invariant Feature Transform" /><meta property="og:locale" content="en" /><meta name="description" content="Scale-invariant Feature Transform, also known as SIFT, is a method to consistently represent features in an image even under different scales, rotations and lighting conditions. Since the video series by First Principles of Computer Vision covers the details very well, the post covers mainly my intuition. The topic requires prior knowledge on using Laplacian of Gaussian for edge detection in images." /><meta property="og:description" content="Scale-invariant Feature Transform, also known as SIFT, is a method to consistently represent features in an image even under different scales, rotations and lighting conditions. Since the video series by First Principles of Computer Vision covers the details very well, the post covers mainly my intuition. The topic requires prior knowledge on using Laplacian of Gaussian for edge detection in images." /><link rel="canonical" href="https://yarkhinephyo.github.io/posts/primer-to-sift/" /><meta property="og:url" content="https://yarkhinephyo.github.io/posts/primer-to-sift/" /><meta property="og:site_name" content="Phyo’s Log" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-04-13T01:30:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Primer to Scale-invariant Feature Transform" /><meta name="google-site-verification" content="2UleTuNSIWIpwLx2fe8HmZnxBJIFsf8S8208z2wBbc4" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-01-21T02:17:58+00:00","datePublished":"2022-04-13T01:30:00+00:00","description":"Scale-invariant Feature Transform, also known as SIFT, is a method to consistently represent features in an image even under different scales, rotations and lighting conditions. Since the video series by First Principles of Computer Vision covers the details very well, the post covers mainly my intuition. The topic requires prior knowledge on using Laplacian of Gaussian for edge detection in images.","headline":"Primer to Scale-invariant Feature Transform","mainEntityOfPage":{"@type":"WebPage","@id":"https://yarkhinephyo.github.io/posts/primer-to-sift/"},"url":"https://yarkhinephyo.github.io/posts/primer-to-sift/"}</script><title>Primer to Scale-invariant Feature Transform | Phyo's Log</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Phyo's Log"><meta name="application-name" content="Phyo's Log"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.25.0/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/me_2.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a><h1 class="site-title"> <a href="/">Phyo's Log</a></h1><p class="site-subtitle fst-italic mb-0">Thoughts on tech and random things that I read. For my future self with goldfish memory.</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/timeline/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>TIMELINE</span> </a><li class="nav-item"> <a href="/about-me/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT ME</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <a href="https://github.com/yarkhinephyo" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="javascript:location.href = 'mailto:' + ['yarkhinephyo','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/yar-khine-phyo/" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Primer to Scale-invariant Feature Transform</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>Primer to Scale-invariant Feature Transform</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1649813400" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Apr 13, 2022 </time> </span> <span> Updated <time data-ts="1705803478" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jan 21, 2024 </time> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/yarkhinephyo">Yar Khine Phyo</a> </em> </span> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="929 words" > <em>5 min</em> read</span></div></div></header><div class="content"><p>Scale-invariant Feature Transform, also known as SIFT, is a method to consistently represent features in an image even under different scales, rotations and lighting conditions. Since the video series by First Principles of Computer Vision covers the details very well, the post covers mainly my intuition. The topic requires prior knowledge on using <a href="https://en.wikipedia.org/wiki/Discrete_Laplace_operator">Laplacian of Gaussian</a> for edge detection in images.</p><h3 id="why-extract-features"><span class="me-2">Why extract features?</span><a href="#why-extract-features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/img/2022-04-13-1.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-1.jpg" alt="" loading="lazy"></a> <em>Image by First Principles of Computer Vision</em></p><p>Consider the two images. How can the computer recognize that the object in the left is included inside the image on the right? One way is to use <a href="https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html">template-based matching</a> where the left image is overlapped onto the right. Then some form of similarity measure can be calculated as it is shifted across the right image.</p><p><ins>Problem</ins>: To ensure different scales are accounted for, we would need templates of different sizes. To check for different orientations, we would need a template for every unit of angle. To overcome occlusion, we may even need to split the left image into multiple pieces and check if each of them matches.</p><p><a href="/assets/img/2022-04-13-2.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-2.jpg" alt="" loading="lazy"></a></p><p>For the example above, our brains recognize the eye and the faces to locate the book. Our eyes do not scan every pixel, and we are not affected by the differences in scale and rotation. Similarly it will be great if we can <strong>1)</strong> extract only interesting features from an image and <strong>2)</strong> transform them into representations that are consistent across different scenes.</p><h3 id="good-requirements-for-feature-representation"><span class="me-2">Good requirements for feature representation</span><a href="#good-requirements-for-feature-representation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><ins>Points of Interest</ins>: Blob-like features with rich details are preferred over simple corners or edges.</p><p><ins>Insensitive to Scale</ins>: The feature representation should be normalized to its size.</p><p><ins>Insensitive to Rotation</ins>: The feature representation should be able to undo the effects of rotation.</p><p><ins>Insensitive to Lighting</ins>: The feature representation should be consistent under different lighting conditions.</p><h3 id="blob-detection---scale-normalized-points-of-interest"><span class="me-2">Blob detection - Scale-normalized points of interest</span><a href="#blob-detection---scale-normalized-points-of-interest" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/img/2022-04-13-3.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-3.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429 - 1D edge detection</em></p><p>In traditional edge detection, a Laplacian operator can be applied to an image through convolution. Edges can be identified from the <em>ripples</em> in the response.</p><p><a href="/assets/img/2022-04-13-4.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-4.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429 - 1D blob detection</em></p><p>If multiple edges are at the right distance, there will be a single strong <em>ripple</em> caused by constructive interference. If this response is sufficiently strong, the location is identified as a <ins>blob</ins> representing a feature. Intuitively, complex features will be chosen compared to simple edges as constructive interferences cannot be produced by single edges.</p><p>From the same diagram, we can also see that not all collection of edges result in singular <em>ripples</em> with a particular Laplacian operator. By increasing the <ins>sigma (σ)</ins> of the Laplacian (making the kernel “fatter”), the constructive interference will occur when edges are further apart. If we apply the Laplacian operators many times with varying σ’s, blobs of different scales can be identified each time.</p><p><a href="/assets/img/2022-04-13-5.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-5.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429 - Increasing σ to identify larger blobs</em></p><p>Wait but if the σ is larger, the Laplacian response will be weaker (shown above). Intuitively, if the responses by larger blobs are penalized for their sizes. Does that means the selected features will be mostly tiny?</p><p><a href="/assets/img/2022-04-13-6.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-6.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429 - Normalized Laplacian of the Gaussian (NLoG)</em></p><p>We solve this by multiplying the Laplacian response with σ<sup>2</sup> for normalization. (This works out because the Laplacian is the 2nd Gaussian derivative) Intuitively, this means that the response now only indicates the <ins>complexity</ins> of the features without any effect from their sizes.</p><p><a href="/assets/img/2022-04-13-7.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-7.jpg" alt="" loading="lazy"></a> <em>3 x 3 x 3 kernels to find local extremas</em></p><p>Imagine the Laplacian response represented as a matrix with <em>x</em>-<em>y</em> plane for image dimensions and <em>z</em> axis for various σ. We can slide an <em>n x n x n</em> kernel to find the local extremas. The resulting <em>x</em>-<em>y</em> coordinates would represent the centers of the blobs and σ would correspond to their sizes.</p><p>With this technique, blobs can be extracted to represent complex features with the sizes normalized.</p><h3 id="countering-the-effects-of-rotation"><span class="me-2">Countering the effects of rotation</span><a href="#countering-the-effects-of-rotation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/img/2022-04-13-8.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-8.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429</em></p><p>To assign an orientation to each feature, it can be divided into smaller windows as shown above. Then the pixel gradient for each window can be computed to produce a histogram of gradient directions. The most prominent direction can be assigned as the <ins>principle orientation</ins> of the feature.</p><p><a href="/assets/img/2022-04-13-9.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-9.jpg" alt="" loading="lazy"></a> <em>Image by Author</em></p><p>In the example above, blobs are identified in both images representing the same feature. The black arrows are the principle orientations. After rescaling the blob sizes with the corresponding σ’s, the effect of rotation is eliminated by aligning with respect to the principle orientations.</p><h3 id="countering-the-effects-of-lighting-conditions"><span class="me-2">Countering the effects of lighting conditions</span><a href="#countering-the-effects-of-lighting-conditions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/img/2022-04-13-10.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-10.jpg" alt="" loading="lazy"></a> <em>Image from Princeton CS429 - Pixels to SIFT descriptors</em></p><p>Instead of comparing each blob directly (pixel-by-pixel), we can produce a unique representation that is invariant to lighting conditions. As shown above, the image can be broken into smaller windows (4 x 4) where each histogram of the gradients is computed. If each histogram only consider 8 directions, there will be 8 dimensions per window. Even with only 16 windows per blob, each feature representation will be of 128 dimensions (16 x 8) which can be robust.</p><p>These feature representations are known more formally as <ins>SIFT descriptors</ins>.</p><h3 id="conclusion"><span class="me-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/img/2022-04-13-11.jpg" class="popup img-link shimmer"><img src="/assets/img/2022-04-13-11.jpg" alt="" loading="lazy"></a> <em>Image from OpenCV documentation</em></p><p>For matching images, SIFT descriptors in two images can be directly compared against one another through similarity measurements. If a large number of them matches, it is likely that the same objects are observed in both images. In practice, nearest neighbor algorithms such as <a href="https://github.com/flann-lib/flann">FLANN</a> are used to match the features between images.</p><h3 id="resources"><span class="me-2">Resources</span><a href="#resources" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ol><li><a href="https://www.youtube.com/watch?v=IBcsS8_gPzE&amp;list=PL2zRqk16wsdqXEMpHrc4Qnb5rA1Cylrhx&amp;index=16">SIFT Detector by First Principles of Computer Vision</a><li><a href="https://www.cs.princeton.edu/courses/archive/fall17/cos429/notes/cos429_fall2017_lecture4_interest_points.pdf">Feature Detectors and Descriptors - Princeton CS429</a></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/tech/">Tech</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/data-science/" class="post-tag no-text-decoration" >Data-Science</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Primer%20to%20Scale-invariant%20Feature%20Transform%20-%20Phyo's%20Log&url=https%3A%2F%2Fyarkhinephyo.github.io%2Fposts%2Fprimer-to-sift%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Primer%20to%20Scale-invariant%20Feature%20Transform%20-%20Phyo's%20Log&u=https%3A%2F%2Fyarkhinephyo.github.io%2Fposts%2Fprimer-to-sift%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fyarkhinephyo.github.io%2Fposts%2Fprimer-to-sift%2F&text=Primer%20to%20Scale-invariant%20Feature%20Transform%20-%20Phyo's%20Log" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/containers-under-the-hood/">Learning Points: Containers Under the Hood</a><li class="text-truncate lh-lg"> <a href="/posts/hashicorp-vault/">Learning Points: Hashicorp Vault</a><li class="text-truncate lh-lg"> <a href="/posts/cassandra-as-a-service/">Learning Points: Cassandra as a Service (AstraDB)</a><li class="text-truncate lh-lg"> <a href="/posts/large-pages-in-linux-kernel/">Learning Points: Large Pages in the Linux Kernel</a><li class="text-truncate lh-lg"> <a href="/posts/linux-perf-monitoring-tools/">Learning Points: Linux Performance Tools</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/learning-points/">Learning-Points</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">System-Design</a> <a class="post-tag btn btn-outline-primary" href="/tags/networking/">Networking</a> <a class="post-tag btn btn-outline-primary" href="/tags/operating-system/">Operating-System</a> <a class="post-tag btn btn-outline-primary" href="/tags/database/">Database</a> <a class="post-tag btn btn-outline-primary" href="/tags/c/">C</a> <a class="post-tag btn btn-outline-primary" href="/tags/concurrency/">Concurrency</a> <a class="post-tag btn btn-outline-primary" href="/tags/data-engineering/">Data-Engineering</a> <a class="post-tag btn btn-outline-primary" href="/tags/data-science/">Data-Science</a> <a class="post-tag btn btn-outline-primary" href="/tags/git/">Git</a></div></section></div><section id="toc-wrapper" class="ps-0 pe-4"><h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/intuition-behind-the-attention-head/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1649485200" data-df="ll" > Apr 9, 2022 </time><h4 class="pt-0 my-2">Intuition Behind the Attention Head of Transformers</h4><div class="text-muted"><p> Even as I frequently use transformers for NLP projects, I have struggled with the intuition behind the multi-head attention mechanism outlined in the paper - Attention Is All You Need. This post wi...</p></div></div></a></article><article class="col"> <a href="/posts/snowflake-new-streams-talk/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1705803600" data-df="ll" > Jan 21, 2024 </time><h4 class="pt-0 my-2">Learning Points: Snowflake Iceberg, Streaming, Unistore</h4><div class="text-muted"><p> This video is about Snowflake Iceberg Tables, Streaming Ingest and Unistore. The presenters are N.Single, T.Jones and A.Motivala as part of the Database Seminar Series by CMU Database Group. Probl...</p></div></div></a></article><article class="col"> <a href="/posts/streamlining-fedramp-compliance/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1705809300" data-df="ll" > Jan 21, 2024 </time><h4 class="pt-0 my-2">Learning Points: Streamlining FedRAMP Compliance with CNCF</h4><div class="text-muted"><p> This video is about streamlining FedRAMP compliance with CNCF technologies. The presenters are Ali Monfre and Vlad Ungureanu from Palantir Technologies. FedRAMP Overview FedRAMP is the accreditat...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/intuition-behind-the-attention-head/" class="btn btn-outline-primary" aria-label="Older" ><p>Intuition Behind the Attention Head of Transformers</p></a> <a href="/posts/git-submodules-cheatsheet/" class="btn btn-outline-primary" aria-label="Newer" ><p>Git Submodules Cheatsheet</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p> © <time>2024</time> <a href="https://github.com/yarkhinephyo">Yar Khine Phyo</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/learning-points/">Learning-Points</a> <a class="post-tag btn btn-outline-primary" href="/tags/system-design/">System-Design</a> <a class="post-tag btn btn-outline-primary" href="/tags/networking/">Networking</a> <a class="post-tag btn btn-outline-primary" href="/tags/operating-system/">Operating-System</a> <a class="post-tag btn btn-outline-primary" href="/tags/database/">Database</a> <a class="post-tag btn btn-outline-primary" href="/tags/c/">C</a> <a class="post-tag btn btn-outline-primary" href="/tags/concurrency/">Concurrency</a> <a class="post-tag btn btn-outline-primary" href="/tags/data-engineering/">Data-Engineering</a> <a class="post-tag btn btn-outline-primary" href="/tags/data-science/">Data-Science</a> <a class="post-tag btn btn-outline-primary" href="/tags/git/">Git</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.25.0/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/unregister.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-KGM14E7CDB"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-KGM14E7CDB'); }); </script> <script> /* Note: dependent library will be loaded in `js-selector.html` */ SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5"></p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
